{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroProducer\n",
    "from resources.parameters import params\n",
    "\n",
    "class QueryProducer:\n",
    "    def __init__(self):\n",
    "        self._seed = random.randint(1, 3650)\n",
    "        self._params = params\n",
    "        self._schemas()\n",
    "        self._initProducer()\n",
    "    \n",
    "    def _schemas(self):\n",
    "        self._keySchema = avro.load(\"schemas/keyschema.avsc\")\n",
    "        self._valueSchema = avro.load(\"schemas/valueschema.avsc\")\n",
    "            \n",
    "    \n",
    "    def _initProducer(self):\n",
    "        self._producer = AvroProducer(config = self._params[\"consumerconfig\"]\n",
    "                                     , default_key_schema = self._keySchema\n",
    "                                     , default_value_schema = self._valueSchema\n",
    "                                     )\n",
    "        \n",
    "        self._producer.flush()\n",
    "        \n",
    "    def _produce_msg(self, value):\n",
    "        self._seed += 1\n",
    "        random.seed(self._seed)\n",
    "        \n",
    "        key = \"\".join(random\\\n",
    "                      .SystemRandom()\\\n",
    "                      .choice(string.ascii_uppercase + string.digits) for _ in range(10)\n",
    "                      )\n",
    "        \n",
    "        self._producer.produce(topic = self._params[\"topic\"]\n",
    "                              , key = key\n",
    "                              , value = value\n",
    "                              )\n",
    "    \n",
    "    @property\n",
    "    def msg(self):\n",
    "        return self._msg\n",
    "    \n",
    "    @msg.setter\n",
    "    def send(self, msg):\n",
    "        self._msg = msg\n",
    "        self._produce_msg(self._msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.parameters import params\n",
    "from confluent_kafka.avro import AvroConsumer\n",
    "\n",
    "class QueryConsumer:\n",
    "    def __init__(self):\n",
    "        self._params = params\n",
    "        self._switch = False\n",
    "        self._initConsumer()\n",
    "    \n",
    "    def _initConsumer(self):\n",
    "        self._consumer = AvroConsumer(config = self._params[\"consumerconfig\"])\n",
    "        self._consumer.subscribe([self._params[\"topic\"]])\n",
    "        \n",
    "    def _pollMsg(self):\n",
    "        while self._switch:\n",
    "            try:\n",
    "                msg = self._consumer.poll(0)\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if msg is not None:\n",
    "                    return msg.key(), msg.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class Pipe(QueryConsumer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._queue = []\n",
    "    \n",
    "    def queue(self):\n",
    "        return self._queue\n",
    "    \n",
    "    def _trigger(self):\n",
    "        self._query = self._pollMsg()\n",
    "    \n",
    "    @property\n",
    "    def on(self):\n",
    "        self._switch = True\n",
    "        self.thread = Thread(target = self._trigger)\n",
    "        self.thread.start()\n",
    "\n",
    "        return self\n",
    "        \n",
    "    @property\n",
    "    def off(self):\n",
    "        self._switch = False\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def _query(self):\n",
    "        return self._msg\n",
    "        \n",
    "    @_query.setter\n",
    "    def _query(self, msg):\n",
    "        self._msg = msg\n",
    "        if msg is not None:\n",
    "            self._queue.append(msg)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KafkaException",
     "evalue": "KafkaError{code=_INVALID_ARG,val=-186,str=\"No such configuration property: \"max.poll.interval\"\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKafkaException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b740591a6876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryProducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-4df67b0d7134>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schemas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initProducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_schemas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4df67b0d7134>\u001b[0m in \u001b[0;36m_initProducer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         self._producer = AvroProducer(config = self._params[\"consumerconfig\"]\n\u001b[1;32m     21\u001b[0m                                      \u001b[0;34m,\u001b[0m \u001b[0mdefault_key_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                      \u001b[0;34m,\u001b[0m \u001b[0mdefault_value_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_valueSchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                                      )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/confluent_kafka/avro/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, default_key_schema, default_value_schema, schema_registry)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot pass schema_registry along with schema.registry.url config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAvroProducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMessageSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema_registry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_key_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKafkaException\u001b[0m: KafkaError{code=_INVALID_ARG,val=-186,str=\"No such configuration property: \"max.poll.interval\"\"}"
     ]
    }
   ],
   "source": [
    "producer = QueryProducer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Pipe at 0x7fccfc295b38>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tosend = \"\"\"\n",
    "{\n",
    "    \"brand\":\"brandA\"\n",
    "    , \"itemName\":\"tenisA\"\n",
    "    , \"itemSpec\":\"seriaA\"\n",
    "    , \"color\":\"white\"\n",
    "    , \"size\":\"40\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "msg = json.loads(tosend)\n",
    "\n",
    "producer.send = msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.thread.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Pipe at 0x7fccfc295b38>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
